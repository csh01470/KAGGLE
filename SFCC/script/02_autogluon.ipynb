{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474d0294",
   "metadata": {},
   "source": [
    "# KAGGLE : **San Francisco Crime Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dded5c",
   "metadata": {},
   "source": [
    "## __. **REFERENCE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794c63a8",
   "metadata": {},
   "source": [
    "#### __.1. **COLUMNS SPECIFICATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d6c383",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b39a9b22",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b5ff9",
   "metadata": {},
   "source": [
    "## 00. **SET WORK ENVORINMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546dfa4d",
   "metadata": {},
   "source": [
    "#### 00.1. **DEFINE PRE-VARIABELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eab113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 2024\n",
    "compet_nm = 'SFCC'\n",
    "run_time_limit = 60*60*3 # 3 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142c44f",
   "metadata": {},
   "source": [
    "#### 00.2. **IMPORT PACKAGES AND SET OPTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f313a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Import packages\n",
    "import os\n",
    "import warnings\n",
    "import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import shap\n",
    "\n",
    "#(2) Set system options\n",
    "warnings.filterwarnings(action='ignore')\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3abfe3f",
   "metadata": {},
   "source": [
    "#### 00.3. **CREATE FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7a3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Create `relocate_col()` function\n",
    "def relocate_col(df:pd.DataFrame, tar_col:str, std_col:str, how:str='after') -> pd.DataFrame : \n",
    "    '''\n",
    "    Reorder columns in a DataFrame by moving a target column relative to a standard column.\n",
    "\n",
    "    Parameters :\n",
    "    - df (pd.DataFrame): The DataFrame from which the column will be relocated.\n",
    "    - tar_col (str): The name of the column to be relocated.\n",
    "    - std_col (str): The column relative to which `tar_col` will be relocated.\n",
    "    - how (str, optional): Specifies the placement of `tar_col` relative to `std_col`.\n",
    "      It can be 'after' (default) or 'before'.\n",
    "\n",
    "    Returns :\n",
    "    - pd.DataFrame: A new DataFrame with the column `tar_col` relocated as specified.\n",
    "    '''\n",
    "    col_ary = np.array(object=df.columns)\n",
    "    tar_col_idx = np.where(col_ary==tar_col)[0][0]\n",
    "    std_col_idx = np.where(col_ary==std_col)[0][0]\n",
    "    col_ary = np.delete(arr=col_ary, obj=tar_col_idx)\n",
    "    if how == 'after' : \n",
    "        if std_col_idx == len(col_ary) : \n",
    "            col_ary = np.insert(arr=col_ary, obj=std_col_idx, values=tar_col)\n",
    "        else :\n",
    "            col_ary = np.insert(arr=col_ary, obj=std_col_idx+1, values=tar_col)\n",
    "    elif how == 'before' : \n",
    "        if std_col_idx == 0 : \n",
    "            col_ary = np.insert(arr=col_ary, obj=std_col_idx, values=tar_col) \n",
    "        else : \n",
    "            col_ary = np.insert(arr=col_ary, obj=std_col_idx-1, values=tar_col)\n",
    "    else : \n",
    "        pass\n",
    "    df = df.loc[:, col_ary]\n",
    "    return df \n",
    "\n",
    "#(2) Create `diagnose_df()` function\n",
    "def diagnose_df(df:pd.DataFrame) -> pd.DataFrame : \n",
    "    '''\n",
    "    Generates a diagnostic summary for a pandas DataFrame, reporting details like data types, \n",
    "    count of missing values, and uniqueness for each column.\n",
    "\n",
    "    Parameters :\n",
    "    - df (pd.DataFrame): The DataFrame to be diagnosed.\n",
    "\n",
    "    Returns :\n",
    "    - pd.DataFrame: A summary table with diagnostics for each column in the input DataFrame, \n",
    "      including the column name, data type, total rows, count and rate of missing values, \n",
    "      and count and rate of unique values.\n",
    "    '''\n",
    "    output = pd.DataFrame(data=df.dtypes).reset_index()\n",
    "    output.columns = ['COLUMN_NM', 'DATA_TYPE']\n",
    "    output.loc[:, 'ROW_CNT'] = len(df)\n",
    "    output.loc[:, 'NA_CNT'] = df.isna().sum().values\n",
    "    output.loc[:, 'NA_RATE'] = output.loc[:, 'NA_CNT'] / output.loc[:, 'ROW_CNT']\n",
    "    output.loc[:, 'UNIQUE_CNT'] = df.nunique().values\n",
    "    output.loc[:, 'UNIQUE_RATE'] = output.loc[:, 'UNIQUE_CNT'] / output.loc[:, 'ROW_CNT']\n",
    "    format_columns = ['ROW_CNT', 'NA_CNT', 'UNIQUE_CNT']\n",
    "    for col in format_columns:\n",
    "        output[col] = output[col].apply(func=lambda x: f'{x:,.0f}')\n",
    "    return output\n",
    "\n",
    "#(3) Create `diagnose_num_df()` function\n",
    "def diagnose_num_df(df:pd.DataFrame) -> pd.DataFrame : \n",
    "    '''\n",
    "    Generates a diagnostic summary for numeric columns in a pandas DataFrame, including statistical \n",
    "    measures like mean, median, mode, and various percentiles.\n",
    "\n",
    "    Parameters :\n",
    "    - df (pd.DataFrame): The DataFrame to be diagnosed. Only numeric columns will be considered.\n",
    "\n",
    "    Returns :\n",
    "    - pd.DataFrame: A summary table with diagnostics for each numeric column in the input DataFrame, \n",
    "      including count, mean, standard deviation, min, max, median, mode, and various percentiles.\n",
    "    '''\n",
    "    df = df.select_dtypes(include='number')\n",
    "    output = df.describe(include='all', percentiles=[0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99]).transpose()\n",
    "    output.loc[:, 'median'] = df.median()\n",
    "    output.loc[:, 'mode'] = df.mode().values[0]\n",
    "    output = relocate_col(df=output, tar_col='median', std_col='mean', how='after')\n",
    "    output = relocate_col(df=output, tar_col='mode', std_col='median', how='after')\n",
    "    output.columns = np.array(object=list(map(np.char.upper, output.columns)))\n",
    "    output = output.rename(columns={'COUNT' : 'ROW_CNT'})\n",
    "    output['ROW_CNT'] = output['ROW_CNT'].astype(dtype='int')\n",
    "    return output\n",
    "\n",
    "#(3) Create `split_dt()` function\n",
    "def split_dt(df:pd.DataFrame, tar_col:str) -> pd.DataFrame :\n",
    "    output = df.copy()\n",
    "    output.loc[:, 'year'] = output.loc[:, tar_col].dt.strftime(date_format='%Y').astype(dtype='int')\n",
    "    output.loc[:, 'month'] = output.loc[:, tar_col].dt.strftime(date_format='%m').astype(dtype='int')\n",
    "    output.loc[:, 'day'] = output.loc[:, tar_col].dt.strftime(date_format='%d').astype(dtype='int')\n",
    "    output.loc[:, 'hour'] = output.loc[:, tar_col].dt.strftime(date_format='%H').astype(dtype='int')\n",
    "    output.loc[:, 'minute'] = output.loc[:, tar_col].dt.strftime(date_format='%M').astype(dtype='int')\n",
    "    output = relocate_col(df=output, tar_col='year', std_col=tar_col, how='after')\n",
    "    output = relocate_col(df=output, tar_col='month', std_col='year', how='after')\n",
    "    output = relocate_col(df=output, tar_col='day', std_col='month', how='after')\n",
    "    output = relocate_col(df=output, tar_col='hour', std_col='day', how='after')\n",
    "    output = relocate_col(df=output, tar_col='minute', std_col='hour', how='after')\n",
    "    output = output.drop(labels=tar_col, axis=1)\n",
    "    return output\n",
    "\n",
    "#(4)\n",
    "def split_addr(df:pd.DataFrame, tar_col:str) -> pd.DataFrame : \n",
    "    output = df.copy()\n",
    "    output.loc[:, 'Address'] = output.loc[:, 'Address'].str.replace(pat=r'  ', repl=' ')\n",
    "    ###\n",
    "\n",
    "    ###\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f45cce",
   "metadata": {},
   "source": [
    "#### 00.4. **CREATE CLASSES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5ec89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Create `AutogluonWrapper`\n",
    "class AutogluonWrapper :\n",
    "    def __init__(self, predictor, feature_names, target_class=None):\n",
    "        self.ag_model = predictor\n",
    "        self.feature_names = feature_names\n",
    "        self.target_class = target_class\n",
    "        if target_class is None and predictor.problem_type != 'regression' :\n",
    "            print(\"Since target_class not specified, SHAP will explain predictions for each class\")\n",
    "    \n",
    "    def predict_proba(self, X) :\n",
    "        if isinstance(X, pd.Series):\n",
    "            X = X.values.reshape(1,-1)\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.feature_names)\n",
    "        preds = self.ag_model.predict_proba(X)\n",
    "        if self.ag_model.problem_type == \"regression\" or self.target_class is None:\n",
    "            return preds\n",
    "        else:\n",
    "            return preds[self.target_class]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59968db6",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9b111",
   "metadata": {},
   "source": [
    "## 01. **READ AND CONCATENATE DATASETS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d03c9",
   "metadata": {},
   "source": [
    "##### 01.1. **READ DATASETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83cbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Read Datasets\n",
    "train_raw = pd.read_table(filepath_or_buffer=f'{os.getcwd()}/../data/train.csv', sep=',')\n",
    "test_raw = pd.read_table(filepath_or_buffer=f'{os.getcwd()}/../data/test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41faa6ef",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e63c3e",
   "metadata": {},
   "source": [
    "## 02. **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e9c81a",
   "metadata": {},
   "source": [
    "#### 02.1. **CHECK DATASET SHAPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299aeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'>> Train raw dataset shape : {train_raw.shape}')\n",
    "print(f'>> Test raw dataset shape : {test_raw.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ba71e",
   "metadata": {},
   "source": [
    "#### 02.2. **CHECK COLUMN NOT IN TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e48c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON = ~(np.isin(element=train_raw.columns, test_elements=test_raw.columns))\n",
    "train_raw.columns[CON]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd706bc4",
   "metadata": {},
   "source": [
    "#### 02.3. **DIAGNOSE DATASETS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47a002",
   "metadata": {},
   "source": [
    "##### 02.3.1. **CHECK _**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Diagnose `train_raw`\n",
    "diag_train = diagnose_df(df=train_raw)\n",
    "\n",
    "#(2) Print `diag_train`\n",
    "diag_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b64b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3) Diagnose `test_raw`\n",
    "diag_test = diagnose_df(df=test_raw)\n",
    "\n",
    "#(4) Print `diag_test`\n",
    "diag_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29eef41",
   "metadata": {},
   "source": [
    "##### 02.3.2. **CHECK _**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d678532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5) Check numerical columns (descriptive statistics)\n",
    "num_cols = train_raw.select_dtypes(include=['float', 'int']).columns\n",
    "\n",
    "#(6) Diagnose number columns\n",
    "diagnose_num_df(df=train_raw.loc[:, num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d566e",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5332832",
   "metadata": {},
   "source": [
    "## 03. **CLEANSE DATASETS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17edf16c",
   "metadata": {},
   "source": [
    "##### 03.1. **SET FORMAT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b85726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) \n",
    "train = train_raw.copy()\n",
    "test = test_raw.copy()\n",
    "\n",
    "#(2)\n",
    "train = train.drop_duplicates()\n",
    "\n",
    "#(3)\n",
    "train = train.drop(labels=['Descript', 'Resolution'], axis=1)\n",
    "test = test.drop(labels=['Id'], axis=1)\n",
    "\n",
    "#(3)\n",
    "train = relocate_col(df=train, tar_col='Category', std_col=train.columns[-1], how='after')\n",
    "\n",
    "#(4)\n",
    "train['Dates'] = pd.to_datetime(arg=train['Dates'], errors='coerce')\n",
    "test['Dates'] = pd.to_datetime(arg=test['Dates'], errors='coerce')\n",
    "\n",
    "#(5)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(6)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73b4bc",
   "metadata": {},
   "source": [
    "#### 03.2. **_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfdf8a4",
   "metadata": {},
   "source": [
    "##### 03.2.1. **SPLIT DATE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c372ca7",
   "metadata": {},
   "source": [
    "- `YYYY-mm-DD HH:MM:SS` $ \\rightarrow{} $ `YYYY` / `mm` / `DD` / `HH` / `MM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fa022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "train = split_dt(df=train, tar_col='Dates')\n",
    "test = split_dt(df=test, tar_col='Dates')\n",
    "\n",
    "#(2)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045683d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a4ed2",
   "metadata": {},
   "source": [
    "##### 03.2.2. **_ ADDRESS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f7cf4",
   "metadata": {},
   "source": [
    "- `[\\s{2,}]` $ \\rightarrow{} $ `[\\s]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23410314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "train = split_addr(df=train, tar_col='Address')\n",
    "test = split_addr(df=test, tar_col='Address')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18fb076",
   "metadata": {},
   "source": [
    "##### 03.2.3. **MODIFY ABBREVIATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e3698",
   "metadata": {},
   "source": [
    "- AL :\n",
    "\n",
    "- AV :\n",
    "\n",
    "- BL :\n",
    "\n",
    "- CR :\n",
    "\n",
    "- CT :\n",
    "\n",
    "- DR :\n",
    "\n",
    "- EX :\n",
    "\n",
    "- HY : \n",
    "\n",
    "- LN : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb16f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2)\n",
    "temp = train.loc[:, 'Address'].str.split(pat=' ')\n",
    "# temp = temp.explode().tolist()\n",
    "# temp = list(np.unique(ar=temp))\n",
    "# temp\n",
    "np.unique(ar=temp.apply(lambda x: x[-1]).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88e53c",
   "metadata": {},
   "source": [
    "#### 03.3. **DIAGNOSE DATASETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424368be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Diagnose `train`\n",
    "diagnose_df(df=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2) Diagnose `test`\n",
    "diagnose_df(df=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fbf38e",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63e919",
   "metadata": {},
   "source": [
    "## 04. **BUILD MODELS BY `AUTO-GLUON`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2b583d",
   "metadata": {},
   "source": [
    "#### 04.0. **ABOUT `AUTO-GLUON`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2621b7cc",
   "metadata": {},
   "source": [
    "- ðŸ“ƒ [API document](https://auto.gluon.ai/stable/index.html)\n",
    "\n",
    "- ðŸ“ƒ [paper](https://arxiv.org/pdf/2003.06505)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64320662",
   "metadata": {},
   "source": [
    "#### 04.1. **SET UP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a3ee8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Define `req_dttm`\n",
    "req_dttm = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "#(1) Define `predictor`\n",
    "predictor = TabularPredictor(\n",
    "    label='Category',\n",
    "    eval_metric='log_loss',\n",
    "    problem_type='multiclass',\n",
    "    path=f'../temp/ATOGL_{req_dttm}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1676cead",
   "metadata": {},
   "source": [
    "#### 04.2. **FIT TRAIN DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e7e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.fit(\n",
    "    train_data=train,\n",
    "    excluded_model_types=['KNN'],\n",
    "    presets='best_quality',\n",
    "    # num_bag_folds=10,\n",
    "    # auto_stack=True,\n",
    "    num_cpus='auto',\n",
    "    num_gpus='auto',\n",
    "    time_limit=run_time_limit,\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7cf588",
   "metadata": {},
   "source": [
    "#### 04.3. **CHECK SCORE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(extra_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b8006",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58aa8ac",
   "metadata": {},
   "source": [
    "## 05. **CHECK MODEL INTERPRETABILITY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8115d76f",
   "metadata": {},
   "source": [
    "#### 05.1. **CHECK FEATURE-IMPORTANCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe924fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Print feature importance\n",
    "predictor.feature_importance(data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a3ee21",
   "metadata": {},
   "source": [
    "#### 05.2. **CHECK SHAPLY VALUE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049af021",
   "metadata": {},
   "source": [
    "##### 05.2.1. **SET UP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f771678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "X_train_pp = predictor.transform_features(data=train).astype(dtype=float)\n",
    "X_test_pp = predictor.transform_features(data=test).astype(dtype=float)\n",
    "\n",
    "#(2)\n",
    "# baseline = X_train_pp.loc[:, :].sample(n=100, random_state=seed_num)\n",
    "\n",
    "#(3)\n",
    "ag_wrapper = AutogluonWrapper(predictor=predictor, feature_names=X_train_pp.columns, target_class=train.loc[:, 'Category'])\n",
    "# explainer = shap.KernelExplainer(model=ag_wrapper.predict_proba, data=X_train_pp)\n",
    "# print(f'>> Baseline prediction : {np.mean(ag_wrapper.predict_proba(X=baseline)):.4f}')  # this is the same as explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58436a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3)\n",
    "# shap_samples = 15\n",
    "# shap_values = explainer.shap_values(X=X_train_pp, nsamples=shap_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b648bb76",
   "metadata": {},
   "source": [
    "##### 05.2.3. **DRAW FORCE PLOT (ONE-SAMPLE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0281514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Draw force plot by 1 sample\n",
    "# row_idx = 0  # index of an example datapoint\n",
    "\n",
    "#(2)\n",
    "# single_datapoint = X_train_pp.iloc[[row_idx], :]\n",
    "# single_prediction = ag_wrapper.predict_proba(X=single_datapoint)\n",
    "\n",
    "#(3)\n",
    "# shap_values_single = explainer.shap_values(X=single_datapoint, nsamples=shap_samples)\n",
    "# shap.force_plot(explainer.expected_value, shap_values_single, X_train_pp.iloc[row_idx, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4fcd3",
   "metadata": {},
   "source": [
    "##### 05.2.4. **DRAW FORCE PLOT (N-SAMPLES)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994a403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.force_plot(base_value=explainer.expected_value, shap_values=shap_values, features=X_test_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c8901",
   "metadata": {},
   "source": [
    "##### 05.2.5. **DRAW SUMMARY PLOT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2fc09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values=shap_values, features=X_test_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff8dcb9",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566514c3",
   "metadata": {},
   "source": [
    "## 06. **PREDICT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f68148f",
   "metadata": {},
   "source": [
    "#### 06.1. **PREDICT TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Make `pred`\n",
    "pred = pd.DataFrame(data={\n",
    "   'Id'       : test_raw.loc[:, 'Id'].values,\n",
    "   'Category' : predictor.predict(data=test).values\n",
    "})\n",
    "\n",
    "#(2) Print `pred`\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8560c06",
   "metadata": {},
   "source": [
    "#### 06.2. **WRITE PREDICT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede36b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #(1) Define `submission_nm`\n",
    "# submission_nm = f'atogl_stacking_{req_dttm}'\n",
    "\n",
    "# #(2) Write `pred`\n",
    "# pred.loc[:, ['id', 'class']].to_csv(path_or_buf=f'../output/{compet_nm}_{submission_nm}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9045607,
     "sourceId": 76727,
     "sourceType": "competition"
    },
    {
     "datasetId": 478,
     "sourceId": 974,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ATOGL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 159.349778,
   "end_time": "2024-08-04T03:40:44.363345",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-04T03:38:05.013567",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
